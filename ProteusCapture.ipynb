{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "##################################################################################################################\n",
        "#\n",
        "# GuitarML Proteus Colab Capture Instructions\n",
        "#\n",
        "#  Step 1. Click \"Runtime\" in the Colab top menu bar, then \"Change Runtime Type\"\n",
        "#          and select \"GPU\" and save. You have a limited number of consecutive GPU hours with\n",
        "#          the free version of Colab, but this will reset in a day or so. \n",
        "#\n",
        "#  Step 2. Upload your recorded output from your device by dragging and dropping the \"out.wav\"\n",
        "#          file to the file browser in the left hand window in Colab. Ensure that this file is named\n",
        "#          \"out.wav\".\n",
        "#\n",
        "#  Step 3. Run the SETUP ENVIRONMENT section by clicking the run arrow on the top left of the box.\n",
        "#          Should take a few minutes. Scroll down to next step when finished.\n",
        "#\n",
        "#  Step 4. Choose one (and only one) of the next 3 options as applicable to your captured device. This\n",
        "#          will begin the model training process. It should take about 10 minutes with GPU runtime selected.\n",
        "#          The training may finish before reaching 300 epochs, this is normal.\n",
        "#          \n",
        "#  Step 5. Run this section to generate a Proteus compatible model file. Download from the \n",
        "#          left hand file browser by right clicking the \"newProteusModel.json\" filename in the left hand menu and \n",
        "#          selecting \"Download\". May need to refresh the filebrowser by clicking the refresh folder icon.\n",
        "#\n",
        "#  Step 6. Optionally, generate a plot of the signals to visually see how close the model is \n",
        "#          to the actual device. \n",
        "#\n",
        "#  Note: Recommended to \"Disconnect and delete runtime\" from the \"Runtime\" menu and \"Reconnect\" to reset the environment\n",
        "#     when training additional models. Make sure to download your trained model before disconnecting.\n",
        "#\n",
        "#  Note: To continue to refine the model, you may run the same Step 4 (a,b,c) after changing the \"-eps\" field to \n",
        "#     the number of epochs to continue training.\n",
        "#     For example, in Step 4c., change \"-eps 300\" to \"-eps 100\" to run an additional 100 epochs. \n",
        "#     Then re-run Step 5 to generate a new Proteus compatible model. \n",
        "#\n",
        "##################################################################################################################\n"
      ],
      "metadata": {
        "id": "DSQzuJkLidpz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3 : SETUP ENVIRONMENT\n",
        "# Run this block to setup environment. May take a few minutes.\n",
        "\n",
        "!git clone https://github.com/GuitarML/Automated-GuitarAmpModelling.git\n",
        "%cd Automated-GuitarAmpModelling/\n",
        "!git checkout proteus-capture\n",
        "!git submodule update --init --recursive"
      ],
      "metadata": {
        "id": "pzrdkYdTd3cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4a. Run this to start capture of CLEAN AMP, EDGE OF BREAKUP AMP, COMPRESSOR\n",
        "model=\"amp_clean\"\n",
        "!python prep_wav.py $model -s Data/Proteus_Capture.wav ../out.wav --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -eps 300"
      ],
      "metadata": {
        "id": "ri7QM2j5ipyb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4b. Run this to start capture of MEDIUM to HIGH GAIN AMP\n",
        "model=\"amp_gain\"\n",
        "!python prep_wav.py $model -s Data/Proteus_Capture.wav ../out.wav --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -eps 300"
      ],
      "metadata": {
        "id": "8DUec-jId3Ti"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4c.  Run this to start capture of OVERDRIVE, DISTORTION, or BOOST PEDAL\n",
        "model=\"pedal\"\n",
        "!python prep_wav.py $model -s Data/Proteus_Capture.wav ../out.wav --normalize true\n",
        "!python dist_model_recnet.py -l \"RNN3-\"$model -eps 300"
      ],
      "metadata": {
        "id": "3Xiq856Ii0ba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 5. After Above Capture Process is Completed, Run this to generate a Proteus compatible model file.\n",
        "#         The model file will be located in the top level folder with the name \"newProteusModel.json\"\n",
        "#         May need to refresh the left hand file browser by clicking the refresh folder icon.\n",
        "#         Right click the file and choose download, then rename as appropriate.\n",
        "\n",
        "%cp \"Results/\"$model\"-RNN3-\"$model\"/model_best.json\" ../newProteusModel.json"
      ],
      "metadata": {
        "id": "j4ypBZrXi5jM"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 6. (Optional) After above Capture Process is completed, Run this to generate data graphs of the device model\n",
        "#         The PNG image will be located in the top level folder with the name \"detail_signal_comparison_e2s...\".\n",
        "#         May need to refresh the left hand file browser by clicking the refresh folder icon.\n",
        "\n",
        "# Double click the PNG file to view the graphs. These graphs show approximately 10 milliseconds of audio signal. \n",
        "# The top plot shows the input signal. The middle plot shows the target device signal vs the signal \n",
        "#      predicted by the new model. The goal is for these signals to be as close as possible.\n",
        "\n",
        "!python plot.py $model\n",
        "%cp \"Results/\"$model\"-RNN3-\"$model\"/\"$model\"_Detail\"* ../"
      ],
      "metadata": {
        "id": "Z2u4IKm_d3Oh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## TROUBLESHOOTING NOTES ##\n",
        "\n",
        "# 1. Training will go through 300 epochs, beginning with a pre-trained starting point model.\n",
        "#    The number of epochs can be adjusted by changing the \"-eps\" value in the dist_model_recnet.py \n",
        "#    line on step 4 (a,b,c). You can run the same training step again to refine the model, and stop at any time. \n",
        "#\n",
        "# 2. This catpure method is limited to non-time based effects (no Delay, Reverb, Flange, Phaser, etc.) \n",
        "#      It is intended for Amplifiers, Distortion/Overdrive/Boost and Compression(results on compressors vary)\n",
        "# "
      ],
      "metadata": {
        "id": "mwHTeJ6Kd3Lg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "Welcome To Colaboratory",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}