{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c85348f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-Parameterized Data\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:89: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  in_rate, in_data = wavfile.read(args.in_file)\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:90: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  out_rate, out_data = wavfile.read(args.out_file)\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:91: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  test_in_rate, test_in_data = wavfile.read(args.test_in_file)\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:92: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  test_out_rate, test_out_data = wavfile.read(args.test_out_file)\r\n"
     ]
    }
   ],
   "source": [
    "!python prep_wav.py \\\n",
    "\"./Recordings/20211003_LPB-1_5_min_Pink_Ramp_Clean.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_5_min_Pink_Ramp_Dirty.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_Natalie_Guitar_Clean.wav\" \\\n",
    "\"./Recordings/20211003_LPB-1_Natalie_Guitar_Dirty.wav\" \\\n",
    "\"LPB1_50\" --normalize true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fae3ae9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing model file found, loading network\n",
      "cuda device available\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "Epoch:  1\n",
      "current learning rate: 0.005\n",
      "Epoch:  2\n",
      "Val loss: tensor(0.0783)\n",
      "current learning rate: 0.005\n",
      "Epoch:  3\n",
      "current learning rate: 0.005\n",
      "Epoch:  4\n",
      "Val loss: tensor(0.0388)\n",
      "current learning rate: 0.005\n",
      "Epoch:  5\n",
      "current learning rate: 0.005\n",
      "Epoch:  6\n",
      "Val loss: tensor(0.0295)\n",
      "current learning rate: 0.005\n",
      "Epoch:  7\n",
      "current learning rate: 0.005\n",
      "Epoch:  8\n",
      "Val loss: tensor(0.0724)\n",
      "current learning rate: 0.005\n",
      "Epoch:  9\n",
      "current learning rate: 0.005\n",
      "Epoch:  10\n",
      "Val loss: tensor(0.0366)\n",
      "current learning rate: 0.005\n",
      "Epoch:  11\n",
      "current learning rate: 0.005\n",
      "Epoch:  12\n",
      "Val loss: tensor(0.0206)\n",
      "current learning rate: 0.005\n",
      "Epoch:  13\n",
      "current learning rate: 0.005\n",
      "Epoch:  14\n",
      "Val loss: tensor(0.0212)\n",
      "current learning rate: 0.005\n",
      "Epoch:  15\n",
      "current learning rate: 0.005\n",
      "Epoch:  16\n",
      "Val loss: tensor(0.0214)\n",
      "current learning rate: 0.005\n",
      "Epoch:  17\n",
      "current learning rate: 0.005\n",
      "Epoch:  18\n",
      "Val loss: tensor(0.0213)\n",
      "current learning rate: 0.005\n",
      "Epoch:  19\n",
      "current learning rate: 0.005\n",
      "Epoch:  20\n",
      "Val loss: tensor(0.0298)\n",
      "current learning rate: 0.005\n",
      "Epoch:  21\n",
      "current learning rate: 0.005\n",
      "Epoch:  22\n",
      "Val loss: tensor(0.0125)\n",
      "current learning rate: 0.005\n",
      "Epoch:  23\n",
      "current learning rate: 0.005\n",
      "Epoch:  24\n",
      "Val loss: tensor(0.0268)\n",
      "current learning rate: 0.005\n",
      "Epoch:  25\n",
      "current learning rate: 0.005\n",
      "Epoch:  26\n",
      "Val loss: tensor(0.0168)\n",
      "current learning rate: 0.005\n",
      "Epoch:  27\n",
      "current learning rate: 0.005\n",
      "Epoch:  28\n",
      "Val loss: tensor(0.0075)\n",
      "current learning rate: 0.005\n",
      "Epoch:  29\n",
      "current learning rate: 0.005\n",
      "Epoch:  30\n",
      "Val loss: tensor(0.0081)\n",
      "current learning rate: 0.005\n",
      "Epoch:  31\n",
      "current learning rate: 0.005\n",
      "Epoch:  32\n",
      "Val loss: tensor(0.0060)\n",
      "current learning rate: 0.005\n",
      "Epoch:  33\n",
      "current learning rate: 0.005\n",
      "Epoch:  34\n",
      "Val loss: tensor(0.0053)\n",
      "current learning rate: 0.005\n",
      "Epoch:  35\n",
      "current learning rate: 0.005\n",
      "Epoch:  36\n",
      "Val loss: tensor(0.0057)\n",
      "current learning rate: 0.005\n",
      "Epoch:  37\n",
      "current learning rate: 0.005\n",
      "Epoch:  38\n",
      "Val loss: tensor(0.0130)\n",
      "current learning rate: 0.005\n",
      "Epoch:  39\n",
      "current learning rate: 0.005\n",
      "Epoch:  40\n",
      "Val loss: tensor(0.0047)\n",
      "current learning rate: 0.005\n",
      "Epoch:  41\n",
      "current learning rate: 0.005\n",
      "Epoch:  42\n",
      "Val loss: tensor(0.0043)\n",
      "current learning rate: 0.005\n",
      "Epoch:  43\n",
      "current learning rate: 0.005\n",
      "Epoch:  44\n",
      "Val loss: tensor(0.0042)\n",
      "current learning rate: 0.005\n",
      "Epoch:  45\n",
      "current learning rate: 0.005\n",
      "Epoch:  46\n",
      "Val loss: tensor(0.0072)\n",
      "current learning rate: 0.005\n",
      "Epoch:  47\n",
      "current learning rate: 0.005\n",
      "Epoch:  48\n",
      "Val loss: tensor(0.0059)\n",
      "current learning rate: 0.005\n",
      "Epoch:  49\n",
      "current learning rate: 0.005\n",
      "Epoch:  50\n",
      "Val loss: tensor(0.0081)\n",
      "current learning rate: 0.005\n",
      "Epoch:  51\n",
      "current learning rate: 0.005\n",
      "Epoch:  52\n",
      "Val loss: tensor(0.0043)\n",
      "current learning rate: 0.005\n",
      "Epoch:  53\n",
      "current learning rate: 0.005\n",
      "Epoch:  54\n",
      "Val loss: tensor(0.0055)\n",
      "current learning rate: 0.005\n",
      "Epoch:  55\n",
      "current learning rate: 0.005\n",
      "Epoch:  56\n",
      "Epoch    28: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Val loss: tensor(0.0056)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  57\n",
      "current learning rate: 0.0025\n",
      "Epoch:  58\n",
      "Val loss: tensor(0.0044)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  59\n",
      "current learning rate: 0.0025\n",
      "Epoch:  60\n",
      "Val loss: tensor(0.0072)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  61\n",
      "current learning rate: 0.0025\n",
      "Epoch:  62\n",
      "Val loss: tensor(0.0041)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  63\n",
      "current learning rate: 0.0025\n",
      "Epoch:  64\n",
      "Val loss: tensor(0.0044)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  65\n",
      "current learning rate: 0.0025\n",
      "Epoch:  66\n",
      "Val loss: tensor(0.0050)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  67\n",
      "current learning rate: 0.0025\n",
      "Epoch:  68\n",
      "Val loss: tensor(0.0045)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  69\n",
      "current learning rate: 0.0025\n",
      "Epoch:  70\n",
      "Val loss: tensor(0.0038)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  71\n",
      "current learning rate: 0.0025\n",
      "Epoch:  72\n",
      "Val loss: tensor(0.0038)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  73\n",
      "current learning rate: 0.0025\n",
      "Epoch:  74\n",
      "Val loss: tensor(0.0052)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  75\n",
      "current learning rate: 0.0025\n",
      "Epoch:  76\n",
      "Val loss: tensor(0.0048)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  77\n",
      "current learning rate: 0.0025\n",
      "Epoch:  78\n",
      "Val loss: tensor(0.0057)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  79\n",
      "current learning rate: 0.0025\n",
      "Epoch:  80\n",
      "Val loss: tensor(0.0037)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  81\n",
      "current learning rate: 0.0025\n",
      "Epoch:  82\n",
      "Val loss: tensor(0.0049)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  83\n",
      "current learning rate: 0.0025\n",
      "Epoch:  84\n",
      "Val loss: tensor(0.0036)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  85\n",
      "current learning rate: 0.0025\n",
      "Epoch:  86\n",
      "Val loss: tensor(0.0038)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  87\n",
      "current learning rate: 0.0025\n",
      "Epoch:  88\n",
      "Val loss: tensor(0.0059)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  89\n",
      "current learning rate: 0.0025\n",
      "Epoch:  90\n",
      "Val loss: tensor(0.0067)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  91\n",
      "current learning rate: 0.0025\n",
      "Epoch:  92\n",
      "Val loss: tensor(0.0048)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  93\n",
      "current learning rate: 0.0025\n",
      "Epoch:  94\n",
      "Val loss: tensor(0.0061)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  95\n",
      "current learning rate: 0.0025\n",
      "Epoch:  96\n",
      "Val loss: tensor(0.0035)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  97\n",
      "current learning rate: 0.0025\n",
      "Epoch:  98\n",
      "Val loss: tensor(0.0036)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  99\n",
      "current learning rate: 0.0025\n",
      "Epoch:  100\n",
      "Val loss: tensor(0.0038)\n",
      "current learning rate: 0.0025\n",
      "Done Training\n",
      "Testing the final Model\n",
      "Testing the best Model\n",
      "Finished Training: SimpleRNNLPB1_50_LSTM_hs20_pre_high_pass\n"
     ]
    }
   ],
   "source": [
    "!python dist_model_recnet.py -l RNN3-LPB1 -eps 100 --seed 39\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "7e3e47f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameterized Data\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:193: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  in_rate, in_data = wavfile.read(file_map[param][0])\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:194: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  out_rate, out_data = wavfile.read(file_map[param][1])\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:195: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  test_in_rate, test_in_data = wavfile.read(file_map[param][2])\r\n",
      "/home/micahtseng/Personal/mlamsk/python3Env/pytorchSandbox/Automated-GuitarAmpModelling/prep_wav.py:196: WavFileWarning: Chunk (non-data) not understood, skipping it.\r\n",
      "  test_out_rate, test_out_data = wavfile.read(file_map[param][3])\r\n"
     ]
    }
   ],
   "source": [
    "!python prep_wav.py \"bla\" \"bla\" \"bla\" \"bla\" \"LPB1_Parameterized_20211027\" -p true\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d300edcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "existing model file found, loading network\n",
      "cuda device available\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "unimplemented audio data type conversion...\n",
      "Epoch:  1\n",
      "current learning rate: 0.005\n",
      "Epoch:  2\n",
      "Val loss: tensor(0.7114)\n",
      "current learning rate: 0.005\n",
      "Epoch:  3\n",
      "current learning rate: 0.005\n",
      "Epoch:  4\n",
      "Val loss: tensor(0.6855)\n",
      "current learning rate: 0.005\n",
      "Epoch:  5\n",
      "current learning rate: 0.005\n",
      "Epoch:  6\n",
      "Val loss: tensor(0.5248)\n",
      "current learning rate: 0.005\n",
      "Epoch:  7\n",
      "current learning rate: 0.005\n",
      "Epoch:  8\n",
      "Val loss: tensor(0.5202)\n",
      "current learning rate: 0.005\n",
      "Epoch:  9\n",
      "current learning rate: 0.005\n",
      "Epoch:  10\n",
      "Val loss: tensor(0.4609)\n",
      "current learning rate: 0.005\n",
      "Epoch:  11\n",
      "current learning rate: 0.005\n",
      "Epoch:  12\n",
      "Val loss: tensor(0.3415)\n",
      "current learning rate: 0.005\n",
      "Epoch:  13\n",
      "current learning rate: 0.005\n",
      "Epoch:  14\n",
      "Val loss: tensor(0.2091)\n",
      "current learning rate: 0.005\n",
      "Epoch:  15\n",
      "current learning rate: 0.005\n",
      "Epoch:  16\n",
      "Val loss: tensor(0.2170)\n",
      "current learning rate: 0.005\n",
      "Epoch:  17\n",
      "current learning rate: 0.005\n",
      "Epoch:  18\n",
      "Val loss: tensor(0.0941)\n",
      "current learning rate: 0.005\n",
      "Epoch:  19\n",
      "current learning rate: 0.005\n",
      "Epoch:  20\n",
      "Val loss: tensor(0.0621)\n",
      "current learning rate: 0.005\n",
      "Epoch:  21\n",
      "current learning rate: 0.005\n",
      "Epoch:  22\n",
      "Val loss: tensor(0.4097)\n",
      "current learning rate: 0.005\n",
      "Epoch:  23\n",
      "current learning rate: 0.005\n",
      "Epoch:  24\n",
      "Val loss: tensor(0.0518)\n",
      "current learning rate: 0.005\n",
      "Epoch:  25\n",
      "current learning rate: 0.005\n",
      "Epoch:  26\n",
      "Val loss: tensor(0.3223)\n",
      "current learning rate: 0.005\n",
      "Epoch:  27\n",
      "current learning rate: 0.005\n",
      "Epoch:  28\n",
      "Val loss: tensor(0.1985)\n",
      "current learning rate: 0.005\n",
      "Epoch:  29\n",
      "current learning rate: 0.005\n",
      "Epoch:  30\n",
      "Val loss: tensor(0.1289)\n",
      "current learning rate: 0.005\n",
      "Epoch:  31\n",
      "current learning rate: 0.005\n",
      "Epoch:  32\n",
      "Val loss: tensor(0.3743)\n",
      "current learning rate: 0.005\n",
      "Epoch:  33\n",
      "current learning rate: 0.005\n",
      "Epoch:  34\n",
      "Val loss: tensor(0.1262)\n",
      "current learning rate: 0.005\n",
      "Epoch:  35\n",
      "current learning rate: 0.005\n",
      "Epoch:  36\n",
      "Epoch    18: reducing learning rate of group 0 to 2.5000e-03.\n",
      "Val loss: tensor(0.0764)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  37\n",
      "current learning rate: 0.0025\n",
      "Epoch:  38\n",
      "Val loss: tensor(0.0646)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  39\n",
      "current learning rate: 0.0025\n",
      "Epoch:  40\n",
      "Val loss: tensor(0.0498)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  41\n",
      "current learning rate: 0.0025\n",
      "Epoch:  42\n",
      "Val loss: tensor(0.0433)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  43\n",
      "current learning rate: 0.0025\n",
      "Epoch:  44\n",
      "Val loss: tensor(0.0484)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  45\n",
      "current learning rate: 0.0025\n",
      "Epoch:  46\n",
      "Val loss: tensor(0.3401)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  47\n",
      "current learning rate: 0.0025\n",
      "Epoch:  48\n",
      "Val loss: tensor(0.1030)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  49\n",
      "current learning rate: 0.0025\n",
      "Epoch:  50\n",
      "Val loss: tensor(0.0741)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  51\n",
      "current learning rate: 0.0025\n",
      "Epoch:  52\n",
      "Val loss: tensor(0.0431)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  53\n",
      "current learning rate: 0.0025\n",
      "Epoch:  54\n",
      "Val loss: tensor(0.0347)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  55\n",
      "current learning rate: 0.0025\n",
      "Epoch:  56\n",
      "Val loss: tensor(0.0304)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  57\n",
      "current learning rate: 0.0025\n",
      "Epoch:  58\n",
      "Val loss: tensor(0.0530)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  59\n",
      "current learning rate: 0.0025\n",
      "Epoch:  60\n",
      "Val loss: tensor(0.0360)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  61\n",
      "current learning rate: 0.0025\n",
      "Epoch:  62\n",
      "Val loss: tensor(0.0330)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  63\n",
      "current learning rate: 0.0025\n",
      "Epoch:  64\n",
      "Val loss: tensor(0.0312)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  65\n",
      "current learning rate: 0.0025\n",
      "Epoch:  66\n",
      "Val loss: tensor(0.3366)\n",
      "current learning rate: 0.0025\n",
      "Epoch:  67\n",
      "current learning rate: 0.0025\n",
      "Epoch:  68\n",
      "Epoch    34: reducing learning rate of group 0 to 1.2500e-03.\n",
      "Val loss: tensor(0.0816)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  69\n",
      "current learning rate: 0.00125\n",
      "Epoch:  70\n",
      "Val loss: tensor(0.0604)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  71\n",
      "current learning rate: 0.00125\n",
      "Epoch:  72\n",
      "Val loss: tensor(0.0451)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  73\n",
      "current learning rate: 0.00125\n",
      "Epoch:  74\n",
      "Val loss: tensor(0.0412)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  75\n",
      "current learning rate: 0.00125\n",
      "Epoch:  76\n",
      "Val loss: tensor(0.0548)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  77\n",
      "current learning rate: 0.00125\n",
      "Epoch:  78\n",
      "Val loss: tensor(0.0259)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  79\n",
      "current learning rate: 0.00125\n",
      "Epoch:  80\n",
      "Val loss: tensor(0.0274)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  81\n",
      "current learning rate: 0.00125\n",
      "Epoch:  82\n",
      "Val loss: tensor(0.0411)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  83\n",
      "current learning rate: 0.00125\n",
      "Epoch:  84\n",
      "Val loss: tensor(0.0267)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  85\n",
      "current learning rate: 0.00125\n",
      "Epoch:  86\n",
      "Val loss: tensor(0.0261)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  87\n",
      "current learning rate: 0.00125\n",
      "Epoch:  88\n",
      "Val loss: tensor(0.0851)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  89\n",
      "current learning rate: 0.00125\n",
      "Epoch:  90\n",
      "Val loss: tensor(0.0243)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  91\n",
      "current learning rate: 0.00125\n",
      "Epoch:  92\n",
      "Val loss: tensor(0.0269)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  93\n",
      "current learning rate: 0.00125\n",
      "Epoch:  94\n",
      "Val loss: tensor(0.0263)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  95\n",
      "current learning rate: 0.00125\n",
      "Epoch:  96\n",
      "Val loss: tensor(0.0274)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  97\n",
      "current learning rate: 0.00125\n",
      "Epoch:  98\n",
      "Val loss: tensor(0.0813)\n",
      "current learning rate: 0.00125\n",
      "Epoch:  99\n",
      "current learning rate: 0.00125\n",
      "Epoch:  100\n",
      "Val loss: tensor(0.0229)\n",
      "current learning rate: 0.00125\n",
      "Done Training\n",
      "Testing the final Model\n",
      "Testing the best Model\n",
      "Finished Training: SimpleRNNLPB1_Parameterized_20211027_LSTM_hs20_pre_high_pass\n"
     ]
    }
   ],
   "source": [
    "!python dist_model_recnet.py -l RNN3-LPB1_Parameterized -eps 100 --seed 39 -is 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
